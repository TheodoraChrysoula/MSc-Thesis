{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96061e33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDMNIST v2.1.0 @ https://github.com/MedMNIST/MedMNIST/\n",
      "The number of classes is: 2 \n",
      " The number of channels is 1.\n",
      "The class_names are {'0': 'normal', '1': 'pneumonia'}\n",
      "{'python_class': 'PneumoniaMNIST', 'description': 'The PneumoniaMNIST is based on a prior dataset of 5,856 pediatric chest X-Ray images. The task is binary-class classification of pneumonia against normal. We split the source training set with a ratio of 9:1 into training and validation set and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−2,916)×(127−2,713). We center-crop the images and resize them into 1×28×28.', 'url': 'https://zenodo.org/record/6496656/files/pneumoniamnist.npz?download=1', 'MD5': '28209eda62fecd6e6a2d98b1501bb15f', 'task': 'binary-class', 'label': {'0': 'normal', '1': 'pneumonia'}, 'n_channels': 1, 'n_samples': {'train': 4708, 'val': 524, 'test': 624}, 'license': 'CC BY 4.0'}\n",
      "Using downloaded and verified file: C:\\Users\\Theodora\\.medmnist\\pneumoniamnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\Theodora\\.medmnist\\pneumoniamnist.npz\n",
      "Dataset PneumoniaMNIST (pneumoniamnist)\n",
      "    Number of datapoints: 4708\n",
      "    Root location: C:\\Users\\Theodora\\.medmnist\n",
      "    Split: train\n",
      "    Task: binary-class\n",
      "    Number of channels: 1\n",
      "    Meaning of labels: {'0': 'normal', '1': 'pneumonia'}\n",
      "    Number of samples: {'train': 4708, 'val': 524, 'test': 624}\n",
      "    Description: The PneumoniaMNIST is based on a prior dataset of 5,856 pediatric chest X-Ray images. The task is binary-class classification of pneumonia against normal. We split the source training set with a ratio of 9:1 into training and validation set and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−2,916)×(127−2,713). We center-crop the images and resize them into 1×28×28.\n",
      "    License: CC BY 4.0\n",
      "==================================================\n",
      "Dataset PneumoniaMNIST (pneumoniamnist)\n",
      "    Number of datapoints: 624\n",
      "    Root location: C:\\Users\\Theodora\\.medmnist\n",
      "    Split: test\n",
      "    Task: binary-class\n",
      "    Number of channels: 1\n",
      "    Meaning of labels: {'0': 'normal', '1': 'pneumonia'}\n",
      "    Number of samples: {'train': 4708, 'val': 524, 'test': 624}\n",
      "    Description: The PneumoniaMNIST is based on a prior dataset of 5,856 pediatric chest X-Ray images. The task is binary-class classification of pneumonia against normal. We split the source training set with a ratio of 9:1 into training and validation set and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−2,916)×(127−2,713). We center-crop the images and resize them into 1×28×28.\n",
      "    License: CC BY 4.0\n",
      "[149 966 268]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\medmnist\\utils.py:25: FutureWarning: `multichannel` is a deprecated argument name for `montage`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  montage_arr = skimage_montage(sel_img, multichannel=(n_channels == 3))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ConvNet import ConvNet\n",
    "from Model_LeNet import LeNet\n",
    "\n",
    "\n",
    "from dataset import train_dataset, test_dataset, train_loader, test_loader, task, n_channels, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12dfe544",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "lr = 0.001\n",
    "num_workers = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c65fe82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MyDropout()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MyDropout()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MyDropout()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2048, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): MyDropout()\n",
       "    (4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvNet(n_channels, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "824b1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    '''\n",
    "    Function to save the trained model \n",
    "    '''\n",
    "   \n",
    "    if model.__class__.__name__ == 'LeNet':\n",
    "        torch.save(model.state_dict(), '../outputs/pneumonia_lenet.ckpt')\n",
    "    else:\n",
    "        torch.save(model.state_dict(), '../outputs/pneumonia_convnet.ckpt')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25e66181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    print('Training')\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0.0\n",
    "    counter = 0\n",
    "    for i, (image, labels) in tqdm(enumerate(trainloader), total = len(trainloader)):\n",
    "        counter += 1\n",
    "        #image, labels = data\n",
    "        image = image.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(image)\n",
    "        \n",
    "        # Calculate the loss\n",
    "        if task == 'multi-label, binary-class':\n",
    "            labels = labels.to(torch.float32)\n",
    "            loss = criterion(outputs, labels)\n",
    "        else:\n",
    "            labels = labels.squeeze().long()\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "        train_running_loss += loss.item()\n",
    "        # Calculate the accuracy\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds==labels).sum().item()\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        #Update teh weights\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Loss and accuracy for the complete epoch\n",
    "    epoch_loss = train_running_loss/counter\n",
    "    epoch_acc = 100.*(train_running_correct/ len(trainloader.dataset))\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c94a78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet\n",
      "[INFO]: Epoch 1 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 81.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.604, training_acc: 74.108\n",
      "==================================================\n",
      "[INFO]: Epoch 2 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 78.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.579, training_acc: 74.214\n",
      "==================================================\n",
      "[INFO]: Epoch 3 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 74.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.573, training_acc: 74.214\n",
      "==================================================\n",
      "[INFO]: Epoch 4 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 78.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.568, training_acc: 74.214\n",
      "==================================================\n",
      "[INFO]: Epoch 5 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 81.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.565, training_acc: 74.214\n",
      "==================================================\n",
      "[INFO]: Epoch 6 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:02<00:00, 72.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.555, training_acc: 74.214\n",
      "==================================================\n",
      "[INFO]: Epoch 7 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 82.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.532, training_acc: 74.405\n",
      "==================================================\n",
      "[INFO]: Epoch 8 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 76.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.499, training_acc: 75.743\n",
      "==================================================\n",
      "[INFO]: Epoch 9 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 74.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.450, training_acc: 79.184\n",
      "==================================================\n",
      "[INFO]: Epoch 10 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:02<00:00, 68.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.410, training_acc: 82.647\n",
      "==================================================\n",
      "[INFO]: Epoch 11 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 79.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.363, training_acc: 84.303\n",
      "==================================================\n",
      "[INFO]: Epoch 12 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:02<00:00, 67.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.337, training_acc: 86.088\n",
      "==================================================\n",
      "[INFO]: Epoch 13 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 81.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.320, training_acc: 86.534\n",
      "==================================================\n",
      "[INFO]: Epoch 14 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 77.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.294, training_acc: 87.234\n",
      "==================================================\n",
      "[INFO]: Epoch 15 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:02<00:00, 72.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.278, training_acc: 88.764\n",
      "==================================================\n",
      "[INFO]: Epoch 16 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 80.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.270, training_acc: 88.976\n",
      "==================================================\n",
      "[INFO]: Epoch 17 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:02<00:00, 73.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.259, training_acc: 89.528\n",
      "==================================================\n",
      "[INFO]: Epoch 18 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 77.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.245, training_acc: 90.017\n",
      "==================================================\n",
      "[INFO]: Epoch 19 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 79.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.243, training_acc: 90.081\n",
      "==================================================\n",
      "[INFO]: Epoch 20 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 80.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.243, training_acc: 90.442\n",
      "==================================================\n",
      "[INFO]: Epoch 21 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 80.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.225, training_acc: 90.994\n",
      "==================================================\n",
      "[INFO]: Epoch 22 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 81.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.227, training_acc: 90.675\n",
      "==================================================\n",
      "[INFO]: Epoch 23 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 80.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.221, training_acc: 91.546\n",
      "==================================================\n",
      "[INFO]: Epoch 24 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 76.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.213, training_acc: 91.504\n",
      "==================================================\n",
      "[INFO]: Epoch 25 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 76.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.209, training_acc: 91.737\n",
      "==================================================\n",
      "[INFO]: Epoch 26 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 81.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.205, training_acc: 91.589\n",
      "==================================================\n",
      "[INFO]: Epoch 27 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 78.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.220, training_acc: 91.504\n",
      "==================================================\n",
      "[INFO]: Epoch 28 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 77.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.200, training_acc: 92.353\n",
      "==================================================\n",
      "[INFO]: Epoch 29 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 79.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.210, training_acc: 92.120\n",
      "==================================================\n",
      "[INFO]: Epoch 30 of 30\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [00:01<00:00, 77.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.206, training_acc: 92.268\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Criterion\n",
    "    if task == 'multi-label, binary-class':\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "        \n",
    "    # model selection\n",
    "    model = ConvNet(n_channels, n_classes)  # LeNet accyracy: 89.075\n",
    "    print(model.__class__.__name__ )\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr, momentum = 0.9)\n",
    "    \n",
    "    # Lists to keep track of losses and accuracies\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    # Starting the training\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
    "        train_epoch_loss, train_epoch_acc = train(model, train_loader, \n",
    "                                                optimizer, criterion)\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        train_acc.append(train_epoch_acc)\n",
    "        \n",
    "        print(f\"Training Loss: {train_epoch_loss:.3f}, training_acc: {train_epoch_acc:.3f}\")\n",
    "        print ('='*50)\n",
    "        \n",
    "    #Save the trained model weights\n",
    "    save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd78ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35acfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db54ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
