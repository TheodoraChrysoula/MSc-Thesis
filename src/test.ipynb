{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e37bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "import medmnist \n",
    "from medmnist import INFO, Evaluator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7de742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDMNIST v2.1.0 @ https://github.com/MedMNIST/MedMNIST/\n",
      "The number of classes is: 2 \n",
      " The number of channels is 1.\n",
      "The class_names are {'0': 'normal', '1': 'pneumonia'}\n",
      "{'python_class': 'PneumoniaMNIST', 'description': 'The PneumoniaMNIST is based on a prior dataset of 5,856 pediatric chest X-Ray images. The task is binary-class classification of pneumonia against normal. We split the source training set with a ratio of 9:1 into training and validation set and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−2,916)×(127−2,713). We center-crop the images and resize them into 1×28×28.', 'url': 'https://zenodo.org/record/6496656/files/pneumoniamnist.npz?download=1', 'MD5': '28209eda62fecd6e6a2d98b1501bb15f', 'task': 'binary-class', 'label': {'0': 'normal', '1': 'pneumonia'}, 'n_channels': 1, 'n_samples': {'train': 4708, 'val': 524, 'test': 624}, 'license': 'CC BY 4.0'}\n",
      "Using downloaded and verified file: C:\\Users\\Theodora\\.medmnist\\pneumoniamnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\Theodora\\.medmnist\\pneumoniamnist.npz\n",
      "Dataset PneumoniaMNIST (pneumoniamnist)\n",
      "    Number of datapoints: 4708\n",
      "    Root location: C:\\Users\\Theodora\\.medmnist\n",
      "    Split: train\n",
      "    Task: binary-class\n",
      "    Number of channels: 1\n",
      "    Meaning of labels: {'0': 'normal', '1': 'pneumonia'}\n",
      "    Number of samples: {'train': 4708, 'val': 524, 'test': 624}\n",
      "    Description: The PneumoniaMNIST is based on a prior dataset of 5,856 pediatric chest X-Ray images. The task is binary-class classification of pneumonia against normal. We split the source training set with a ratio of 9:1 into training and validation set and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−2,916)×(127−2,713). We center-crop the images and resize them into 1×28×28.\n",
      "    License: CC BY 4.0\n",
      "==================================================\n",
      "Dataset PneumoniaMNIST (pneumoniamnist)\n",
      "    Number of datapoints: 624\n",
      "    Root location: C:\\Users\\Theodora\\.medmnist\n",
      "    Split: test\n",
      "    Task: binary-class\n",
      "    Number of channels: 1\n",
      "    Meaning of labels: {'0': 'normal', '1': 'pneumonia'}\n",
      "    Number of samples: {'train': 4708, 'val': 524, 'test': 624}\n",
      "    Description: The PneumoniaMNIST is based on a prior dataset of 5,856 pediatric chest X-Ray images. The task is binary-class classification of pneumonia against normal. We split the source training set with a ratio of 9:1 into training and validation set and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−2,916)×(127−2,713). We center-crop the images and resize them into 1×28×28.\n",
      "    License: CC BY 4.0\n",
      "[210 870  35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\medmnist\\utils.py:25: FutureWarning: `multichannel` is a deprecated argument name for `montage`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  montage_arr = skimage_montage(sel_img, multichannel=(n_channels == 3))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset import train_dataset, test_dataset, n_classes, n_channels, class_names, test_loader, task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9b5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test_results(tensor, labels, output_class, counter):\n",
    "    '''\n",
    "    This function will save a few test images along with the\n",
    "    ground truth label and predicted label annotated on the image\n",
    "    \n",
    "    :param tensor: the image tensor\n",
    "    :param target: the ground truth class\n",
    "    param output_class: the predicted class number\n",
    "    param counter: the test image number\n",
    "    '''\n",
    "    \n",
    "    # Move tensor to cpu and denormalize\n",
    "    image = torch.squeeze(tensor, 0).cpu().numpy()\n",
    "    image = image/2 + 0.5\n",
    "    image = np.transpose(image, (1,2,0))\n",
    "    # Convert to RGB format\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    gt = labels.cpu().numpy()\n",
    "    cv2.putText(\n",
    "    image, f\"GT: {gt}\",\n",
    "    (5,25), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(\n",
    "    image, f\"Pred: {output_class}\",\n",
    "    (5, 55), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "    0.7, (0,255,0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imwrite(f\"../outputs/test_image_{counter}.png\", image*255.)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30fd4a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader, task):\n",
    "    model.eval()\n",
    "    print('Testing the model')\n",
    "    prediction_list = []\n",
    "    ground_truth_list = []\n",
    "    test_running_correct = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(testloader), total = len(testloader)):\n",
    "            counter += 1\n",
    "            image, labels = data\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Forward pass\n",
    "            outputs = model(image)\n",
    "            if task == 'multi-label, binary-class':\n",
    "                predictions = torch.sigmoid(outputs, 1).cpu().numpy()\n",
    "            else:\n",
    "                predictions = F.softmax(outputs, 1).cpu().numpy()\n",
    "            output_class = np.argmax(predictions)\n",
    "\n",
    "            # Append the GT and predictions to the respective lists\n",
    "            prediction_list.append(output_class)\n",
    "            ground_truth_list.append(labels.cpu().detach().numpy().flatten())\n",
    "            # Calculate the accuracy\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            test_running_correct += (preds == labels.squeeze().long()).sum().item()\n",
    "            # Save few test images\n",
    "            if counter % 99 == 0:\n",
    "                save_test_results(image, labels, output_class, counter)\n",
    "        acc = 100.*(test_running_correct/ len(testloader.dataset))\n",
    "        return prediction_list, ground_truth_list, acc\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5aa6ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    model = LeNet(n_channels, n_classes)  # LeNet accyracy: 89.075\n",
    "    print(model.__class__.__name__ )\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load('../outputs/mnist_pneumonia_lenet.ckpt', map_location=torch.device('cpu')))\n",
    "    \n",
    "    prediction_list, ground_truth_list, acc = test(model, test_loader, task)\n",
    "    print(f\"Test accuracy: {acc:.3f}%\")\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Confusion matrix\n",
    "    conf_matrix = confusion_matrix(ground_truth_list, prediction_list)\n",
    "    \n",
    "    plt.figure(figsize=(12,9))\n",
    "\n",
    "    sns.heatmap(\n",
    "    conf_matrix, \n",
    "    annot = True,\n",
    "    xticklabels = class_names,\n",
    "    yticklabels = class_names)\n",
    "    \n",
    "    plt.savefig('../outputs/heatmaps_ConvNet_Pneumonia.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1862c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def test_options():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('model', model = 'LeNet')\n",
    "    parser.add_argument('model.load_state_dict', model.load_state_dict(torch.load('../mnist_pneumonia_lenet')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5e05892",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2838bb1d6b29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#model = LeNet(_channnels, n_classes)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda:0'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprediction_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mground_truth_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#model = LeNet(_channnels, n_classes)\n",
    "print(model.__class__.__name__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "prediction_list, ground_truth_list, acc = test(model, test_loader, task)\n",
    "print(f'Test accuracy: {acc:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0133b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
